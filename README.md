# ğŸ›°ï¸ DetecciÃ³n de AnomalÃ­as en Series Temporales IQ mediante Autoencoders (Conv1D + LSTM)

Este proyecto implementa un sistema completo para detectar **ataques de interferencia (jamming)** en una red de comunicaciones simulada, utilizando **autoencoders para series temporales** basados en **CNN + LSTM**.
La detecciÃ³n se basa en el **error de reconstrucciÃ³n** sobre ventanas de datos IQ.

---

## ğŸ“ Estructura del Proyecto

```
TIME-SERIES-ANOMALY-DETECTION/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pure_samples_1/
â”‚   â”‚   â””â”€â”€ pure_samples_1.csv
â”‚   â”œâ”€â”€ under_attack_samples_1/
â”‚   â”‚   â””â”€â”€ under_attack_samples_1.csv
â”‚   â””â”€â”€ intrusion_detected_plots/
â”‚       â”œâ”€â”€ intrusion_sequence_30.png
â”‚       â”œâ”€â”€ intrusion_sequence_54.png
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_generator.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ hybrid.py
â”‚   â”œâ”€â”€ anomaly_detection.py
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ hybrid_conv_lstm_simple.keras
â”œâ”€â”€ hybrid_conv_lstm_simple_final.keras
â”œâ”€â”€ hybrid_simple_best.keras
â”œâ”€â”€ rnn_autoencoder_model.h5
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Objetivo del Proyecto

Detectar **anomalÃ­as en seÃ±ales IQ** provenientes de un sistema de comunicaciones.
Un ataque jammer introduce patrones anÃ³malos que **incrementan el error de reconstrucciÃ³n del autoencoder**, lo que permite distinguir situaciones normales de eventos maliciosos.

---

# ğŸ”§ Componentes Principales

---

## 1. Data Generator (`data_generator.py`)

El Data Generator:

* Lee archivos `.csv` con muestras IQ.
* Separa parte real e imaginaria.
* Normaliza dinÃ¡micamente por ventana.
* Crea ventanas deslizantes (por defecto `SEQ_LEN = 100`).
* Retorna tensores con forma:

```
(batch_size, seq_len, 2)
```

Incluye caracterÃ­sticas avanzadas:

* Reinicio automÃ¡tico del generador.
* Manejo de archivos grandes sin cargarlos en memoria.
* Compatibilidad con data augmentation en tiempo real.

---

## 2. Modelo HÃ­brido Conv1D + LSTM (`hybrid.py`)

Arquitectura del autoencoder:

### **Encoder**

* Capas `Conv1D` con `BatchNorm` + `MaxPooling`.
* LSTM de 256 unidades para capturar dinÃ¡mica temporal.
* Capa latente entre 32â€“64 dimensiones.

### **Decoder**

* `RepeatVector(seq_len)`
* LSTM de 64 unidades
* Capas densas temporales para reconstruir IQ.

Compilado con:

```python
optimizer = Adam(1e-3)
loss = MeanSquaredError()
```

Entrenado mediante:

```python
train_on_batch(X_aug, X_original)
```

---

## 3. Inferencia y Anomaly Detection (`anomaly_detection.py`)

Incluye:

* CÃ¡lculo de error por ventana (MSE).

* Histogramas de errores.

* SelecciÃ³n automÃ¡tica del **umbral Ã³ptimo** usando:

  ```
  precision_recall_curve â†’ mejor F1
  ```

* GeneraciÃ³n automÃ¡tica de grÃ¡ficos bajo ataque en:

```
data/intrusion_detected_plots/
```

---

# ğŸ§ª Experimentos

---

## ğŸ§ª **Experimento A â€” Convâ€“LSTM + Ruido Gaussiano**

AumentaciÃ³n simple:

```
X_aug = X + N(0, 0.01 * std)
```

**Resultados:**

* Muy buena separaciÃ³n entre pure y jammer.
* **F1 â‰ˆ 0.50** (vs baseline â‰ˆ 0.13).

---

## ğŸ§ª **Experimento B â€” AumentaciÃ³n Avanzada**

Incluye:

* Ruido gaussiano
* Amplitude scaling
* Circular time shifting
* Impulse noise

**Resultados:**

* Mayor robustez general
* F1 se mantiene estable â‰ˆ **0.50**
* LimitaciÃ³n: falta regularizaciÃ³n temporal explÃ­cita.

---

## ğŸ§ª **Experimento C â€” Denoising Autoencoder + RegularizaciÃ³n Temporal**

### âœ” Entrenamiento con ruido pesado

El modelo aprende a reconstruir seÃ±ales limpias a partir de seÃ±ales distorsionadas.

### âœ” RegularizaciÃ³n temporal aÃ±adida

PÃ©rdida total:

```
L = MSE(x, x_hat) + Î» Â· Î£_t (xÌ‚[t+1] â€“ xÌ‚[t])Â²
```

### âœ” Beneficios

* Reduce sobreajuste a transitorios irrelevantes.
* Decoder mÃ¡s estable.
* Aumenta separaciÃ³n entre pure y jammer.
* F1 puede subir a **0.60â€“0.70**.

â¡ï¸ DiseÃ±ado para empujar el sistema hacia la meta **F1 = 0.7â€“0.85**.

---

# ğŸ“Š VisualizaciÃ³n de Intrusiones

El sistema genera imÃ¡genes como:

```
intrusion_detected_plots/
â”‚ intrusion_sequence_30.png
â”‚ intrusion_sequence_54.png
â”‚ ...
```

Cada figura muestra:

* SeÃ±al original vs reconstruida.
* Error punto a punto.
* Marcadores cuando la ventana fue clasificada como anomalÃ­a.

---

# â–¶ï¸ CÃ³mo Entrenar el Modelo

Desde `src/`:

```bash
python hybrid.py
```

Esto:

* Inicializa modelo + generadores.
* Entrena por 30 epochs (configurable).
* Guarda mejores versiones como:

```
hybrid_conv_lstm_simple.keras
hybrid_simple_best.keras
```

---

# â–¶ï¸ CÃ³mo Realizar DetecciÃ³n de AnomalÃ­as

Ejecutar:

```bash
python anomaly_detection.py
```

El script:

* Carga modelo entrenado.
* Procesa seÃ±ales bajo ataque.
* Calcula errores por ventana.
* Determina mejor umbral segÃºn F1.
* Guarda grÃ¡ficos de secuencias anomalÃ­a.

---

# ğŸ“ Requisitos

Archivo `requirements.txt` incluye:

* tensorflow / keras
* numpy
* pandas
* matplotlib
* scikit-learn

InstalaciÃ³n:

```bash
pip install -r requirements.txt
```

---

# ğŸ ConclusiÃ³n

El sistema implementa un pipeline completo para detecciÃ³n de ataques de jamming usando autoencoders temporales con:

* Arquitectura hÃ­brida **CNN + LSTM**
* Data augmentation avanzado
* RegularizaciÃ³n temporal para mejorar discriminaciÃ³n
* Umbral Ã³ptimo automÃ¡tico vÃ­a curva PR

